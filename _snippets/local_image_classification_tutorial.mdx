

All the code for this tutorial can be found on [github](https://github.com/launchflow/buildflow-local-image-classification); we will be walking through this repo step by step.

## Define your Project

Your project is defined by the presence of a `buildflow.yaml` [file](/buildflow/programming-guide/buildflow-yaml) in the root of your project.
This is created when we use the [BuildFlow CLI](/buildflow/reference/cli/init) to create a new project, and doesn't need to be updated unless you need to add something.

Our yaml file defines the following:
- [**project**](/buildflow/programming-guide/buildflow-yaml#project): the name of our project; this can be updated to any string containing lower-case letters and hyphens
- [**pulumi_config**](/buildflow/programming-guide/buildflow-yaml#pulumi-configure): our pulumi configuration; here we say we have one stack that is stored locally
- [**entry_point**](/buildflow/programming-guide/buildflow-yaml#entry-point): defines how our application is run

```yaml
project: buildflow-gcp-image-classification-walkthrough
pulumi_config:
  pulumi_home: .buildflow/_pulumi
  stacks:
    - name: local
      backend_url: file://.buildflow/_pulumi/local
entry_point: main:app
```

## Initialize your Flow

We define our flow in `main.py` this is the entry point we defined in our `buildflow.yaml` file. `app = Flow(...)` creates our [Flow object](/buildflow/programming-guide/flows) which is a container for all of our business logic and resources.
You'll notice we call a couple methods on our flow object.

- **add_service**: attaches a service to our flow. A service is a container of [endpoints](/buildflow/programming-guide/endpoints), our service will be used for allowing users to upload images to our application.
- **add_consumer**: attaches a [consumer](/buildflow/programming-guide/consumers) to our flow. A consumer allows us to asynchronously process image uploads meaning it won't block the users request!

<Tip>
    Since this is local we don't have any primitives to create in our cloud provider. See the GCP or AWS tutorials for an example of that.
</Tip>

```python
from buildflow import Flow

from image_classification.processors.consumer import classify_image
from image_classification.processors.service import service

app = Flow()
app.add_service(service)
app.add_consumer(classify_image)
```

## Add your Dependencies

In `dependencies.py` we set up [dependencies](/buildflow/programming-guide/dependencies) that will be used by our endpoints and consumer. Dependencies allow us to precompute and share code between processors. In our case we want to load the model when we start our application before any data is processed.

We do this by defining the `ModelDep` class and add the decorator `@dependency(scope=Scope.REPLICA)` which annotates the class as a dependency that should be created before a [replica](/buildflow/concepts#replicas) starts to process data.

```python
import os

from buildflow.dependencies import dependency, Scope
from imageai.Classification import ImageClassification


@dependency(scope=Scope.REPLICA)
class ModelDep:
    def __init__(self) -> None:
        self.execution_path = os.path.dirname(os.path.realpath(__file__))
        self.prediction = ImageClassification()
        self.prediction.setModelTypeAsMobileNetV2()
        self.prediction.setModelPath("mobilenet_v2-b0353104.pth")
        self.prediction.loadModel()
```


## Add your Service

In `service.py` we define our actual endpoints that will be called by our users.  First we create a service with `service = Service(...)` then attach endpoints to functions using `@service.endpoint(...)`.

<Tip>
    Remember we attached our service to our flow in `main.py` with `app.add_service`
</Tip>


We define three endpoints here:

- **index**: this endpoint returns a simple HTML page that allows users to upload images.
- **image_upload**: this endpoint allows users to upload an image; then we move it to our image processing folder. It takes in an [UploadFile](/buildflow/programming-guide/requests#uploadfile) which is a file that has been uploaded by a user.
- **image_upload_results**: this endpoint returns a simple HTML page that displays the results of our image classification model. It does this by querying our DuckDB table and then rendering the results as a table.

```python
import os

from buildflow import Service
from buildflow.requests import UploadFile
from buildflow.responses import FileResponse, HTMLResponse
import duckdb
import pandas as pd

from image_classification.primitives import table

service = Service(service_id="image-classification")


@service.endpoint("/", method="GET")
def index():
    return FileResponse("image_classification/processors/index.html")


@service.endpoint("/image-upload", method="POST")
async def image_upload(image_file: UploadFile):
    new_file_path = os.path.join("image_folder", image_file.filename)
    with open(new_file_path, "wb") as f:
        file_bytes = await image_file.read()
        f.write(file_bytes)
    with open(new_file_path, "rb") as f:
        file_bytes = f.read()


def generate_inner_table(row):
    inner_df = pd.DataFrame.from_records(row["classifications"])
    return inner_df.to_html(
        classes="table-auto".split(" "),
        index=False,
        border=1,
    ).replace("\n", "")


@service.endpoint("/image-upload-results", method="GET")
def image_upload_results():
    conn = duckdb.connect(database=table.database, read_only=True)
    df = conn.execute(f"SELECT * FROM {table.table}").fetchdf()
    df["classifications"] = df.apply(generate_inner_table, axis=1)

    return HTMLResponse(
        df.to_html(
            classes="m-5 border-spacing-2 border-collapse border border-slate-500 table-auto".split(
                " "
            ),
            escape=False,
        ).replace("\n", "")
    )
```

## Add Async Processing

`consumer.py` is where we send our images through the model. We do this by attaching the `@consumer` decorator to our 
`classify_image` function.

<Tip>
    Remember we attached our service to our flow in `main.py` with `app.add_consumer`
</Tip>

Our consumer function takes in two arguments:
- **file_event: FileChangeEvent** - this is the input to our consumer that is generate when ever an image is uploaded to our bucket (whenever our endpoint is called).
- **model: ModelDep** - this is the dependency we defined in [dependency.py](/buildflow/tutorial#image-classification-dependencies-py) that loaded the model.

```python
import datetime

from buildflow import consumer
from buildflow.types.local import FileChangeEvent
from image_classification.dependencies import ModelDep
from image_classification.primitives import table, file_stream
from image_classification.schemas import Classification, ImageClassificationRow


@consumer(source=file_stream, sink=table)
def classify_image(
    file_event: FileChangeEvent, model: ModelDep
) -> ImageClassificationRow:
    predictions, probabilities = model.prediction.classifyImage(
        file_event.file_path, result_count=5
    )
    classifications = []
    for predicition, probability in zip(predictions, probabilities):
        classifications.append(Classification(predicition, probability))
    row = ImageClassificationRow(
        image_name=file_event.file_path,
        upload=datetime.datetime.utcnow().isoformat(),
        classifications=classifications,
    )
    print(row)
    return row
```

## Other Files

Some other files we didn't mention that are also in the repo:
- **settings.py** - this loads in a `.env` file for configuring our environment variables
- **schemas.py** - defines our API schemas for request and respones
- **requirements.txt** - defines our python dependencies
- **index.html** - a simple HTML page for uploading images


## Running The Application

<Snippet file="local_image_classification.mdx" />